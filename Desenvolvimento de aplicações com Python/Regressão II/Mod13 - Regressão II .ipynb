{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Regressão múltipla\n",
    "\n",
    "<br>\n",
    "\n",
    "### Índice <a name=\"topo\"></a>\n",
    "\n",
    "1. [Simulando a distribuição de $\\hat{\\beta}$](#1)\n",
    "\n",
    "\n",
    "2. [Testando hipóteses sobre os parâmetros](#2)\n",
    "\n",
    "\n",
    "3. [Variáveis Qualitativas](#3)\n",
    "\n",
    "\n",
    "4. [Qualidade do modelo](#4)\n",
    "    - $R^2$\n",
    "    - AIC\n",
    "    - $R^2_{ajustado}$\n",
    "\n",
    "5. [Seleção de variáveis](#5)\n",
    "    - forward\n",
    "    - backward\n",
    "    - stepwise  \n",
    "\n",
    "6. [Regularização](#6)\n",
    "    - L1 lasso\n",
    "    - L2 ridge\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T16:41:49.323033Z",
     "start_time": "2024-05-17T16:41:48.691386Z"
    }
   },
   "source": [
    "# import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn import metrics\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# from scipy.stats import ks_2samp\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import patsy\n",
    "\n",
    "%matplotlib inline"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Simulando a distribuição de $\\hat{\\beta}$</span><a name=\"1\"></a>\n",
    "[Voltar ao índice](#topo)\n",
    "\n",
    "Vamos 50 observações X e y, com uma associação pré-determinada, seguindo a seguinte equação:\n",
    "\n",
    "$y = 5 + 0.1 x + \\epsilon$\n",
    "\n",
    "com o parâmetro aleatório de erro sendo: $\\epsilon \\thicksim N(0,0.5)$\n",
    "\n",
    "Usando a biblioteca ```random``` do numpy é bem fácil simular estes dados."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T16:41:49.710182Z",
     "start_time": "2024-05-17T16:41:49.323033Z"
    }
   },
   "source": [
    "plt.rc('figure', figsize=(6, 4))\n",
    "\n",
    "N = 50\n",
    "\n",
    "\n",
    "x = np.linspace(0,8,N)\n",
    "y = 5 + .1*x + np.random.randn(N)*.5\n",
    "\n",
    "df1 = pd.DataFrame({'x':x, 'y':y})\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "_ = sns.regplot(x='x', y='y', data = df1, ax = ax)\n",
    "ax.set_xlim(0, 8)\n",
    "ax.set_ylim(3, 8)\n",
    "ticks = ax.set_xticks(list(range(0,9,1)))\n",
    "ticks = ax.set_yticks(list(range(3,9,1)))\n",
    "\n",
    "print(df1.corr())\n",
    "\n",
    "reg = smf.ols('y ~ x', data = df1).fit()\n",
    "reg.summary()"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variações aleatórias\n",
    "\n",
    "Nessa situação, podemos considerar que estamos extraindo 50 observações das variáveis x e y de forma aleatória de uma população com as característias especificadas.\n",
    "\n",
    "Observe que a cada vez que rodamos a célula acima, obtemos um valor distinto de $\\beta$.\n",
    "\n",
    "Vamos fazer isso algumas vezes:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T16:41:56.372492Z",
     "start_time": "2024-05-17T16:41:49.710182Z"
    }
   },
   "source": [
    "betas = []\n",
    "for i in range(2000):\n",
    "    x = np.linspace(0,8,N)\n",
    "    y = .1*x + np.random.randn(N)*.5\n",
    "    df1 = pd.DataFrame({'x':x, 'y':y})\n",
    "    reg = smf.ols('y ~ x', data = df1).fit()\n",
    "    betas.append(reg.params[1])\n"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T16:41:56.860498Z",
     "start_time": "2024-05-17T16:41:56.373494Z"
    }
   },
   "source": [
    "plt.rc('figure', figsize=(20, 10))\n",
    "g = sns.displot([betas], binwidth = .005, height = 5, aspect = 1.5)\n",
    "g.set(xlim=(0, 0.2), ylim=(0, 170))"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que os valores de $\\beta$ estão em torno do verdadeiro valor (0,1), embora sejam aleatórios. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulando sob $H_0$\n",
    "A célula abaixo simula os dados com $\\beta = 0$."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T16:42:03.589500Z",
     "start_time": "2024-05-17T16:41:56.861501Z"
    }
   },
   "source": [
    "betas = []\n",
    "for i in range(2000):\n",
    "    x = np.linspace(0,8,N)\n",
    "    y = 0*x + np.random.randn(N)*.5\n",
    "    df1 = pd.DataFrame({'x':x, 'y':y})\n",
    "    reg = smf.ols('y ~ x', data = df1).fit()\n",
    "    betas.append(reg.params[1])\n",
    "    \n",
    "plt.rc('figure', figsize=(20, 10))\n",
    "g = sns.displot([betas], binwidth = .005, height = 5, aspect = 1.5)\n",
    "g.set(xlim=(-0.15, 0.15), ylim=(0, 170))\n",
    "\n",
    "# sns.displot(betas, binwidth = .005, height = 5, aspect = 1.5)"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que os valores obtidos dos $\\beta$s se concentram em torno do 0,1, e a frequência diminui quanto mais nos afastamos do valor verdadeiro. Essa distribuição tem a \"cara\" de uma distribuição muito conhecida e presente em diversas situações, a distribuição Normal (ou Gaussiana). E sim, sob determinadas circunstâncias, a distribuição do $\\beta$ é de fato Normal e com um desvio padrão conhecido. O desvio padrão de um parâmetro em geral é chamado por outro nome **erro padrão**, e é ele que aparece na saída do statsmodels com o nome de ``` std err ```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Testando hipóteses sobre os parâmetros</span><a name=\"2\"></a>\n",
    "[Voltar ao índice](#topo)\n",
    "\n",
    "Queremos saber se uma variável é relevante. Em geral, transformamos as nossas hipóteses para uma afirmação falseável, e sob a qual conseguimos calcular probabilidades. Dessa forma, podemos formular a seguinte hipótese:\n",
    "\n",
    "$H_0: \\beta = 0$  \n",
    "$H_a: \\beta \\neq 0$\n",
    "\n",
    "Assim, sob $H_0$ temos que $\\hat{\\beta}$ dividido pela estimativa do seu erro padrão (*std err*) tem uma distribuição *t-Student* (que é bem parecida com a normal) centrada em zero. **Esse valor corresponde à coluna ```t```** na saída do statsmodels.    \n",
    "\n",
    "Em termos práticos significa que se $\\beta$ está muito longe do zero (comparado com o seu erro padrão), rejeitamos $H_0$, ou seja, se $H_0$ é falsa, significa que $H_a$ é verdadeira, ou seja, $\\beta$ é diferente de zero, o que significa que a variável é relevante no modelo de regressão. \n",
    "\n",
    "Caso contrário, não consideramos a variável relevante no modelo e ela pode ser retirada do modelo.\n",
    "\n",
    "Se você observou um valor $\\hat{\\beta}_{obs}$ como estimativa do seu beta, uma quantidade muito útil de se calcular é $p(|\\hat{\\beta}|>\\hat{\\beta}_{obs})$\n",
    "\n",
    "Um valor interessante na saída do statsmodels é o ```p>|t|```. Vamos lá: \n",
    "\n",
    "- **$\\hat{\\beta}$ é variável aleatória** ok? Primeiro entenda isso. Ele é uma função dos dados. Como os dados são variáveis aleatórias, qualquer função deles é variável aleatória também. Então ele é variável aleatória.\n",
    "- O **p-value** é a probabilidade de obtermos um $\\hat{\\beta}$ mais extremo (maior em valores absolutos) que o observado na nossa amostra, sob $H_0$.\n",
    "- **Regra prática**: então se o *p-value* é muito pequeno, digamos menor que $(1-\\gamma)$, **rejeitamos $H_0$** pois é muito pouco provável observar um beta como estes que observamos sob $H_0$ (Lembra... $H_0$ indica que $\\beta=0$ e a variável é irrelevante no modelo). Esse $\\gamma$ é o que chamamos de confiança e o $(1-\\gamma)$ de significância. Este é o famoso teste de significância aplicado à regressão.\n",
    "- **Regra de bolso**: muitas pessoas usam 5\\% como referência para o *p-value*, outras usam 1\\%. Esse assunto realmente dá pano pra manga e não vamos entrar na polêmica aqui. Mas em todo caso, lembre-se da frase do Box, de que \"todo modelo está errado\" inclusive o seu (e o meu também). A pergunta é o que torna ele útil? E o *p-value* é sem dúvida um valor muito útil.\n",
    "\n",
    "Vamos ver novamente isso no statsmodels:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T16:42:04.020655Z",
     "start_time": "2024-05-17T16:42:03.591513Z"
    }
   },
   "source": [
    "N = 50\n",
    "\n",
    "\n",
    "x = np.linspace(0,8,N)\n",
    "y = 5 + .1*x + np.random.randn(N)*.5\n",
    "\n",
    "df1 = pd.DataFrame({'x':x, 'y':y})\n",
    "\n",
    "_ = sns.regplot(x='x', y='y', data = df1)\n",
    "print(df1.corr())\n",
    "\n",
    "reg = smf.ols('y ~ x', data = df1).fit()\n",
    "reg.summary()"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos simular um caso em que $H_0$ é verdadeira"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T16:42:10.746581Z",
     "start_time": "2024-05-17T16:42:04.021658Z"
    }
   },
   "source": [
    "betas = []\n",
    "for i in range(2000):\n",
    "    x = np.linspace(0,8,N)\n",
    "    y = 0*x + np.random.randn(N)*.5\n",
    "    df1 = pd.DataFrame({'x':x, 'y':y})\n",
    "    reg = smf.ols('y ~ x', data = df1).fit()\n",
    "    betas.append(reg.params[1])\n",
    "    \n",
    "sns.displot(betas)"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observação sobre o teste de significância\n",
    "Repare que os valores simulados de $\\beta$ se distribuem ao longo do verdadeiro valor, que é o zero neste caso, e chegam bem próximoes de 0.1 e -0.1. Se fazemos o nosso teste com 5% de significância, quer dizer que 5% das vezes (1 em cada 20) $H_0$ vai ser verdadeira, mas vamos ter a conclusão errada. Esse é o famoso **erro tipo I** dos testes de hipóteses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Variáveis qualitativas </span><a name=\"3\"></a>\n",
    "[Voltar ao índice](#topo)\n",
    "\n",
    "Já vimos que para tratar variáveis qualitativas precisamos transformá-las em *dummies*, processo este conhecido como *\"hot encoding\"* ou simplesmente *\"encoding\"*.\n",
    "\n",
    "Antes de partir para o próximo tema, vamos mergulhar um pouco mais fundo no entendimento das variáveis *dummy*."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T16:42:10.786379Z",
     "start_time": "2024-05-17T16:42:10.747613Z"
    }
   },
   "source": [
    "tips = sns.load_dataset(\"tips\")\n",
    "tips['tip_pct'] = tips['tip'] / (tips['total_bill'] - tips['tip'])\n",
    "tips['net_bill'] = tips['total_bill'] - tips['tip']\n",
    "tips.head()"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T16:42:11.135926Z",
     "start_time": "2024-05-17T16:42:10.787383Z"
    }
   },
   "source": [
    "sns.pointplot(y = 'tip', x = 'size', data = tips)"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T16:42:11.144558Z",
     "start_time": "2024-05-17T16:42:11.136929Z"
    }
   },
   "source": [
    "y, x = patsy.dmatrices('tip ~ C(size)', data = tips)\n",
    "x"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T16:42:11.151400Z",
     "start_time": "2024-05-17T16:42:11.145561Z"
    }
   },
   "source": [
    "data = pd.DataFrame({'size': [1, 2, 3, 5, 4]})\n",
    "data"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T16:42:11.159140Z",
     "start_time": "2024-05-17T16:42:11.152403Z"
    }
   },
   "source": [
    "from patsy import dmatrix\n",
    "dmatrix(\"C(size)\", data)"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T16:42:11.168427Z",
     "start_time": "2024-05-17T16:42:11.160143Z"
    }
   },
   "source": [
    "y, x = patsy.dmatrices('tip ~ C(size)', data = tips)\n",
    "x"
   ],
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T16:42:11.198594Z",
     "start_time": "2024-05-17T16:42:11.169430Z"
    }
   },
   "source": [
    "sm.OLS(y, x).fit().summary()"
   ],
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T16:42:11.203549Z",
     "start_time": "2024-05-17T16:42:11.199602Z"
    }
   },
   "source": [
    "1.4375 + 1.1448"
   ],
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T16:42:11.212719Z",
     "start_time": "2024-05-17T16:42:11.204558Z"
    }
   },
   "source": [
    "y, x = patsy.dmatrices('tip ~ C(size, Treatment(2))', data = tips)\n",
    "x"
   ],
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T16:42:11.240948Z",
     "start_time": "2024-05-17T16:42:11.213721Z"
    }
   },
   "source": [
    "sm.OLS(y, x).fit().summary()"
   ],
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Qualidade do modelo e complexidade</span><a name=\"4\"></a>\n",
    "[Voltar ao índice](#topo)\n",
    "\n",
    "Quando fazemos uma regressão múltipla, pelo próprio método de mínimos quadrados ordinários, a métrica $R^2$ vai ser necessariamente melhor sempre que adicionarmos uma variável a mais. Sempre. Por menos sentido que a variável faça, por menos informação que ela agregue, o $R^2$ vai ser maior (ou no pior extremo caso, igual) ao que tínhamos antes.\n",
    "\n",
    "Vamos ver isso na prática na base de gorjetas:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T16:42:11.277364Z",
     "start_time": "2024-05-17T16:42:11.242500Z"
    }
   },
   "source": [
    "reg = smf.ols('tip ~ C(size, Treatment(2)) + np.log(net_bill)', data = tips).fit()\n",
    "reg.summary()"
   ],
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vamos inserir a variavel *day* e checar os resultados"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T16:42:11.315225Z",
     "start_time": "2024-05-17T16:42:11.278366Z"
    }
   },
   "source": [
    "reg = smf.ols('tip ~ C(size, Treatment(2)) + np.log(net_bill) + day', data = tips).fit()\n",
    "reg.summary()"
   ],
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observações\n",
    "\n",
    "- O $R^2$ aumentou, embora a variável adicionada não pareça ser significante.\n",
    "- O $R^2$ sempre vai aumentar. Na pior das hipóteses ele fica igual.\n",
    "- O modelo ficou mais \"complicado\".\n",
    "- Estamos aumentando o risco de \"overfitting\".\n",
    "- Esta variável adicional interfere nas estimativas dos demais parâmetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Navalha de Occam\n",
    "\n",
    "Um princípio conhecido como *[Navalha de Occam](https://en.wikipedia.org/wiki/Occam%27s_razor)* indica que se temos dois modelos com indicadores iguais de qualidade, e um é mais simples, o mais simples é desejável. Dessa forma, diversas propostas surgem na tentativa de \"balisar\" a quantidade de parâmetros no modelo, como o $R^2$-*ajustado* - que sofre uma penalização por cada parâmetro no modelo e o AIC que vamos discutir adiante.\n",
    "\n",
    "Com isso em mente, há na literatura diversas alternativas para se considerar a complexidade do modelo na medida de qualidade, como o critério de Akaike (AIC) e o $R^2-ajustado$.\n",
    "\n",
    "#### AIC\n",
    "\n",
    "*Akaike´s Information Criterion* (ou critério da informação de Akaike). É uma métrica mais \"estatística\" de qualidade de ajuste do modelo, desenhada para comparar modelos com diferentes combinações de variáveis. Quanto menor o AIC, melhor o modelo - ou seja, se colocamos uma nova variável no modelo, por esse critério ela é relevante se o AIC diminuir, e não é relevante caso contrário. \n",
    "\n",
    "Diferente do $R^2$, o AIC depende do tamanho da amostra, de modo que não tem uma 'regra de bolso' do tipo \"perto de 1 é bom\", mas é adequado para comparar modelos na mesma amostra.\n",
    "\n",
    "A Wikipedia tem um artigo interessante sobre o [AIC](https://en.wikipedia.org/wiki/Akaike_information_criterion).\n",
    "\n",
    "#### $R^2-ajustado$\n",
    "\n",
    "O $R^2$-ajustado procura ponderar o incremento em explicação da variabilidade com o incremento em complexidade do modelo em termos de número de parâmetros. Ele aumenta se o $R^2$ aumentar mais do que o esperado \"por acaso\", e diminui caso contrário. Sua fórmula é a seguinte:\n",
    "\n",
    "$$R^2_{aj} = 1- \\left[ \\frac{(1-R^2)(n-1)}{(n-k-1)} \\right]$$\n",
    "\n",
    "#### Observações do exemplo anterior\n",
    "Repare que, no exercício anterior, quando inserimos uma variável irrelevante no modelo, o $R^2$ aumentou, mas o $R^2-ajustado$ diminuiu e o AIC aumentou, sugerindo que esta variável não deve entrar no modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Seleção de modelos </span><a name=\"5\"></a>\n",
    "[Voltar ao índice](#topo)\n",
    "\n",
    "Três algoritmos clássicos na literatura estatística para seleção de variáveis:\n",
    "\n",
    "- *Forward*:  \n",
    "    Parte de um modelo vazio e vai incluindo variáveis estatisticamente relevantes uma a uma, priorizando a mais relevante, até que nenhuma seja incluída. Pode haver alguma variável que deixou de ser relevante na presença daquelas que foram incluídas depois.\n",
    "    1. Definir um limite *LI* de *p-value* para uma variável ser **incluída** no modelo\n",
    "    2. Iniciar com um modelo sem variáveis\n",
    "    3. Para cada variável fora do modelo, testar $\\beta = 0$ na presença das demais - armazenar o *p-value*\n",
    "    4. Se o menor *p-value* for menor que *L*, a variável correspondente é incluída no modelo\n",
    "    5. Repetir 3 e 4 até que não sejam adicionadas variáveis ao modelo\n",
    "    <br><br>\n",
    "- *Backward*:  \n",
    "    Parte de um modelo com todas as variáveis possíveis consideradas e vai removendo-as uma a uma, até que nenhuma seja removida. Pode haver variáveis relevantes ainda após o término.\n",
    "    1. Definir um limite *LE* de *p-value* para uma variável ser **excluída** do modelo\n",
    "    2. Para cada variável incluída no modelo, testar $\\beta = 0$ na presença das demais - armazenar o *p-value*\n",
    "    3. Se o menor *p-value* for maior que *LE*, a variável é excluída do modelo\n",
    "    5. Repetir 3 e 4 até que não sejam excluídas mais variáveis do modelo\n",
    "- *Stepwise*:\n",
    "    É básicamente uma mistura dos dois. Vai incluindo variáveis, eventualmente removendo alguma variável caso seja irrelevante na presença das demais.\n",
    "    \n",
    "**Crítica**: Essa abordagem é criticada na comunidade porque esse *p-value* é tido mais como uma referência. Muitos usam esse algoritmo com o critério de Akaike ao invés do *p-value*, ou mesmo as regularizações L1 e L2, com a qual é possível fazer um *grid search* para buscar melhores resultados em previsão.\n",
    "\n",
    "De qualquer forma, a seleção de um modelo por um desses algoritmos **muito raramente** (pra não dizer nunca) é a escolha final. Sempre há insights e ajustes a serem feitos, categorias a agrupar, variáveis conceitualmente importantes que podem ser priorizadas, multicolinearidade a ser tratada (mais sobre isso adiante), enfim, é um processo meio arte meio ciência suportado por algoritmos menos que executado por algoritmos.\n",
    "\n",
    "O código abaixo foi extraído e adaptado do fórum [*stackovervlow*](https://datascience.stackexchange.com/questions/937/does-scikit-learn-have-a-forward-selection-stepwise-regression-algorithm), da resposta do David Dale."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-05-17T16:44:08.885829Z",
     "start_time": "2024-05-17T16:44:07.584875Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "# \n",
    "# data = load_boston()\n",
    "# X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "# y = data.target\n",
    "\n",
    "# substituindo o load pelo read\n",
    "\n",
    "HousingData = pd.read_csv('../../../../Datasets/HousingData.csv', sep = ',')\n",
    "\n",
    "X = HousingData.drop('MEDV', axis = 1)\n",
    "y = HousingData['MEDV']\n",
    "\n",
    "def stepwise_selection(X, y, \n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.05, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose=True):\n",
    "    \"\"\" Perform a forward-backward feature selection \n",
    "    based on p-value from statsmodels.api.OLS\n",
    "    Arguments:\n",
    "        X - pandas.DataFrame with candidate features\n",
    "        y - list-like with the target\n",
    "        initial_list - list of features to start with (column names of X)\n",
    "        threshold_in - include a feature if its p-value < threshold_in\n",
    "        threshold_out - exclude a feature if its p-value > threshold_out\n",
    "        verbose - whether to print the sequence of inclusions and exclusions\n",
    "    Returns: list of selected features \n",
    "    Always set threshold_in < threshold_out to avoid infinite looping.\n",
    "    See https://en.wikipedia.org/wiki/Stepwise_regression for the details\n",
    "    \"\"\"\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        # forward step\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded, dtype=np.dtype('float64'))\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.index[new_pval.argmin()]\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                 print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        print(\"#############\")\n",
    "        print(included)\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.argmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included\n",
    "\n",
    "variaveis = stepwise_selection(X, y)\n",
    "\n",
    "print('resulting features:')\n",
    "print(variaveis)"
   ],
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Regularização </span><a name=\"6\"></a>\n",
    "[Voltar ao índice](#topo)\n",
    "\n",
    "Regularização (ou *model regularization*) é uma forma de considerar a complexidade adicionada ao modelo e simplificar o modelo, quer seja por deixar os parâmetros menos relevantes, quer seja por retirá-los intrgralmente do modelo.\n",
    "\n",
    "As duas formas mais populares na literatura do aprendizado de máquina são a regularização L1 e a regularização L2:\n",
    "\n",
    "#### Função de perda\n",
    "Vamos relembrar que a nossa regressão é uma regressãod e mínimos quadrados, ou seja, estamos minimizando a função do erro quadrático médio (EQM) em função dos parâmetros do modelo ($\\beta_0, \\beta_1, \\beta_2, ..., \\beta_n$). Nossa função de erro, podemos chamá-la de um nome mais geral: *função de perda* L:\n",
    "\n",
    "$$L = \\sum_{n=1}^{N} \\left( y_i - \\hat{y_i} \\right)^2$$\n",
    "\n",
    "As formas de regularização mais populares introduzem uma \"penalização\" na função de perda devido ao aumento na complexidade do modelo - isto é, devido ao aumento do número de parâmetros (ou variáveis) no modelo.\n",
    "\n",
    "#### Regularização L1 (lasso)\n",
    "A regressão lasso introduz uma penalidade igual ao quadrado da soma dos coeficientes na função de perda:\n",
    "\n",
    "$$L_1 = \\sum_{i=1}^{N} \\left( y_i - \\hat{y_i} \\right)^2 + \\alpha \\sum_{k=0}^{M} \\left| \\beta_k \\right|$$\n",
    "\n",
    "Em que:  \n",
    "- $\\beta_k$ são os parâmetros do modelo (atenção que $\\beta_0$ é o intercepto).\n",
    "- N é o número de observações\n",
    "- M é o número de parâmetros\n",
    "- $\\alpha$ no statsmodels é um *hiperparâmetro* do modelo, que regula a penalidade por complexidade.\n",
    "\n",
    "Dessa forma, minimizando essa função de perda, os parâmetros do modelo tendem a ter valor absoluto menor, e caso tragam mais complexidade que explicação da variância, são \"zerados\", o que significa que a variável correspondente fica é eliminada do modelo.\n",
    "\n",
    "#### Regularização L2 (ridge)\n",
    "Outra forma de regularização é a chamada regularização *ridge*, que minimiza a seguinte perda:\n",
    "\n",
    "$$L_2 = \\sum_{i=1}^{N} \\left( y_i - \\hat{y_i} \\right)^2 + \\alpha \\sum_{k=0}^{M} \\left| \\beta_k \\right|^2$$\n",
    "\n",
    "Em que:  \n",
    "- $\\beta_k$ são os parâmetros do modelo (atenção que $\\beta_0$ é o intercepto).\n",
    "- N é o número de observações\n",
    "- M é o número de parâmetros\n",
    "- $\\alpha$ no statsmodels é um *hiperparâmetro* do modelo, que regula a penalidade por complexidade.\n",
    "\n",
    "Essa regularização é semelhante ao *lasso*, porém a penalização é no valor absoluto dos parâmetros. Diferente do lasso, não costuma \"zerar\" os parâmetros das variáveis menos relevantes, somente reduzir os coeficientes.\n",
    "\n",
    "#### *Elastic net*\n",
    "Uma forma bem popular de regularização de regressão é o *elastic net*, que consiste na mistura dos dois otimizando a seguinte função de perda:\n",
    "\n",
    "$$L_E = \\sum_{i=1}^{N} \\left( y_i - \\hat{y_i} \\right)^2 \n",
    "    + \\alpha \\left( L1_{wt} \\sum_{k=0}^{M} \\left| \\beta_k \\right|\n",
    "                    + (1-L1_{wt}) \\sum_{k=0}^{M} \\left( \\beta_k \\right)^2\n",
    "             \\right)$$\n",
    "\n",
    "com:  \n",
    "- N é o número de observações e M o número de parâmetros\n",
    "- $\\alpha$ sendo o hiperparâmetro que dá importância à penalização  \n",
    "- $L1_{wt}$ sendo um número entre 0 e 1 \n",
    "    - quando vale 1, equivale regulaziração L1 - lasso\n",
    "    - quando 0 equivale a L2 - ridge\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vamos testar\n",
    "\n",
    "Vamos usar o Lasso, pois é uma forma interessante de fazer seleção de variáveis no modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "source": [
    "# Regularization\n",
    "modelo = 'tip ~ C(size) + np.log(net_bill) + smoker + time + day'\n",
    "md = smf.ols(modelo, data = tips)\n",
    "reg = md.fit_regularized(method = 'elastic_net' \n",
    "                         , refit = True\n",
    "                         , L1_wt = 1\n",
    "                         , alpha = 0.01)\n",
    "\n",
    "reg.summary()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def stepwise_selection(X, y, \n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.01, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose=True):\n",
    "    \"\"\" Perform a forward-backward feature selection \n",
    "    based on p-value from statsmodels.api.OLS\n",
    "    Arguments:\n",
    "        X - pandas.DataFrame with candidate features\n",
    "        y - list-like with the target\n",
    "        initial_list - list of features to start with (column names of X)\n",
    "        threshold_in - include a feature if its p-value < threshold_in\n",
    "        threshold_out - exclude a feature if its p-value > threshold_out\n",
    "        verbose - whether to print the sequence of inclusions and exclusions\n",
    "    Returns: list of selected features \n",
    "    Always set threshold_in < threshold_out to avoid infinite looping.\n",
    "    See https://en.wikipedia.org/wiki/Stepwise_regression for the details\n",
    "    \"\"\"\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        # forward step\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            print(included+[new_column])\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.argmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        print(included)\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.argmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "data = load_boston()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "result = stepwise_selection(X, y)\n",
    "\n",
    "print('resulting features:')\n",
    "print(result)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "reg_stepwise = sm.OLS(y, sm.add_constant(pd.DataFrame(X[variaveis]))).fit()\n",
    "reg_stepwise.summary()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Best subsets*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def processSubset(feature_set):\n",
    "    # Fit model on feature_set and calculate RSS\n",
    "    model = sm.OLS(y,X[list(feature_set)])\n",
    "    regr = model.fit()\n",
    "    RSS = ((regr.predict(X[list(feature_set)]) - y) ** 2).sum()\n",
    "    return {\"model\":regr, \"RSS\":RSS}\n",
    "\n",
    "def getBest(k):\n",
    "    \n",
    "    tic = time.time()\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for combo in itertools.combinations(X.columns, k):\n",
    "        results.append(processSubset(combo))\n",
    "    \n",
    "    # Wrap everything up in a nice dataframe\n",
    "    models = pd.DataFrame(results)\n",
    "    \n",
    "    # Choose the model with the highest RSS\n",
    "    best_model = models.loc[models['RSS'].argmin()]\n",
    "    \n",
    "    toc = time.time()\n",
    "    print(\"Processed\", models.shape[0], \"models on\", k, \"predictors in\", (toc-tic), \"seconds.\")\n",
    "    \n",
    "    # Return the best model, along with some other useful information about the model\n",
    "    return best_model"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Could take quite awhile to complete...\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "models_best = pd.DataFrame(columns=[\"RSS\", \"model\"])\n",
    "\n",
    "tic = time.time()\n",
    "for i in range(1,8):\n",
    "    models_best.loc[i] = getBest(i)\n",
    "\n",
    "toc = time.time()\n",
    "print(\"Total elapsed time:\", (toc-tic), \"seconds.\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "models_best"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def processSubset(feature_set):\n",
    "    # Fit model on feature_set and calculate RSS\n",
    "    model = sm.OLS(y,X[list(feature_set)])\n",
    "    regr = model.fit()\n",
    "    RSS = ((regr.predict(X[list(feature_set)]) - y) ** 2).sum()\n",
    "    return {\"model\":regr, \"RSS\":RSS}\n",
    "\n",
    "def getBest(k):\n",
    "    \n",
    "    tic = time.time()\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for combo in itertools.combinations(X.columns, k):\n",
    "        results.append(processSubset(combo))\n",
    "    \n",
    "    # Wrap everything up in a nice dataframe\n",
    "    models = pd.DataFrame(results)\n",
    "    \n",
    "    # Choose the model with the highest RSS\n",
    "    best_model = models.loc[models['RSS'].argmin()]\n",
    "    \n",
    "    toc = time.time()\n",
    "    print(\"Processed\", models.shape[0], \"models on\", k, \"predictors in\", (toc-tic), \"seconds.\")\n",
    "    \n",
    "    # Return the best model, along with some other useful information about the model\n",
    "    return models"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "models = getBest(3)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "source": [
    "models.sort_values('RSS')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "X"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "mu = 0\n",
    "\n",
    "sigma = 1\n",
    "x = np.linspace(-5, 5, 500)\n",
    "plt.plot(x, stats.norm.pdf(x, 0, 1))\n",
    "\n",
    "xinf = np.linspace(-5, stats.norm.ppf(.025, 0, 1), 500)\n",
    "plt.fill_between(xinf, stats.norm.pdf(xinf, 0, 1), color = 'orange')\n",
    "\n",
    "xsup = np.linspace(stats.norm.ppf(.975, 0, 1), 5 , 500)\n",
    "plt.fill_between(xsup, stats.norm.pdf(xsup, 0, 1), color = 'orange')\n",
    "\n",
    "\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "xinf = np.linspace(-5, stats.norm.ppf(.025, 0, 1), 500)\n",
    "plt.fill_between(xinf, stats.norm.pdf(xinf, 0, 1))\n",
    "\n",
    "xsup = np.linspace(stats.norm.ppf(.975, 0, 1), 5 , 500)\n",
    "plt.fill_between(xsup, stats.norm.pdf(xsup, 0, 1))\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import patsy\n",
    "from patsy import balanced\n",
    "from patsy import dmatrix"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "patsy.dmatrix(\"C(a, Diff)\", balanced(a=3))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "balanced(a=3)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from patsy import dmatrix\n",
    "from patsy import demo_data\n",
    "\n",
    "data = demo_data(\"a\", nlevels=3)\n",
    "l = [\"a3\", \"a2\", \"a1\"]\n",
    "\n",
    "dmatrix(\"C(a, levels=l)\", data)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "ordinal = [[0, 0], [0, 1], [1, 1]]\n",
    "\n",
    "dmatrix(\"C(a, ordinal)\", data)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
