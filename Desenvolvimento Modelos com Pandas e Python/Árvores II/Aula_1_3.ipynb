{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Classificação multinomial\n",
    "\n",
    "### Índice <a name=\"topo\"></a>\n",
    "- 1. [Introdução](#1)\n",
    "    - 1.1 [Carregar a base do exemplo](#1.1)\n",
    "    - 1.2 [Dados faltantes](#1.2)\n",
    "    - 1.3 [Descritiva inicial](#1.3)\n",
    "- 2. [Preenchimento de dados faltantes](#2)\n",
    "    - 2.1 [2.1 Análise descritiva: vale a pena preencher ```sex``` com modelo?](#2.1)\n",
    "    - 2.2 [2.2 Modelo de preenchimento](#2.2)\n",
    "- 3. [Classificação multinomial](#3)\n",
    "    - 3.1 [A árvore](#3.1)\n",
    "    - 3.2 [Pós-poda](#3.2)\n",
    "    - 3.3 [A árvore](#3.3)\n",
    "    - 3.4 [Avaliação do resultado](#3.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Introdução <a name=\"1\"></a>\n",
    "[Voltar para o índice](#topo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1.1 Carregando a base de exemplo<a name=\"1.1\"></a>\n",
    "[Voltar para o índice](#topo)\n",
    "\n",
    "Nesta aula vamos trabalhar com a base *penguins*. Essa base pode ser carregada com a ajuda do pacote ```seaborn``` conforme abaixo. Já trabalhamos algumas vezes com ela, ela traz dados biométricos de três raças de pinguins. A nossa tarefa vai ser escrever um algoritmo que classifique o pinguim em uma dessas espécies com base nas características biométricas dele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "pg = sns.load_dataset('penguins')\n",
    "pg.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "source": [
    "pg"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Dados faltantes<a name=\"1.2\"></a>\n",
    "[Voltar para o índice](#topo)  \n",
    "\n",
    "Vamos trabalhar com o *scikitlearn*, o que significa que não podemos ter dados *missing* nem em formato *não numérico* na base. Conforme a análise abaixo, podemos ver que há dois valores missing em quatro variáveis, e a variável ```sex``` possui 11 valores não preenchidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "pg.isna().sum()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Descritiva inicial<a name=\"1.3\"></a>\n",
    "[Voltar para o índice](#topo)  \n",
    "\n",
    "Vamos fazer uma matriz de dispersão (*scatterplot matrix*) para visualizar quão promissora é a classificação das raças de pinguim de acordo com as variáveis biométricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "sns.pairplot(pg, hue='species');"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos nos certificar de que essas duas observações são o mesmo registro. Se for o caso, vai ter baixo impacto no nosso algoritmo elimina-los."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "pg[pg['bill_depth_mm'].isna()]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sim, são as mesmas, então eliminar estas observações implica em perder apenas duas observações (e bem incompletas por sinal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "pg1 = pg[~pg['bill_depth_mm'].isna()].copy()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Preenchimento de dados faltantes<a name=\"2\"></a>\n",
    "[Voltar para o índice](#topo)  \n",
    "\n",
    "Para a variável ```sex```, temos mais 9 registros com dados faltantes. Claro que em se tratando de análise de dados, podemos ter inúmeras alternativas, mas eu vejo aqui três razoáveis com prós e contras:\n",
    "\n",
    "- Eliminar a variável ```sex```. Essa alternativa pode significar abrir mão de uma fonte de varição importante que deve ajdar a classificar os indivíduos em suas respectivas classes.\n",
    "- Eliminar os 9 registros faltantes: parece uma solução ok, mas já vamos para 11 registros eliminados de 344.\n",
    "- Fazer imputação de dados: Isso significa tentar \"adivinhar\" qual o valor para a variável faltante para não perder o registro. Se fizermos isso mal, podemos introduzir ruído na base, por outro lado, recuperamos esses registros.\n",
    "\n",
    "A terceira opção parece mais interessante. Agora... que método podemos utilizar? \n",
    "- Podemos fazer imputação pela moda - utilizar o valor que mais aparece na base.\n",
    "- Imputação aleatória: simplemente sortear um valor conforme a distribuição observada\n",
    "- Ou ainda, a solução que vamos adotar, fazer uma \"imputação por árvore\":\n",
    "    - Vamos construir uma árvore de decisão para classificar o sexo dos pinguins dadas as demais variáveis\n",
    "    - Em seguida vamos usar esta árvore para classificar os valores faltantes.\n",
    "\n",
    "Se a nossa árvore for boa, vamos cometer um erro pequeno, e em todo caso, vamos \"salvar\" as observações com dados faltantes. Como contra, eu apontaria o trabalho de se construir esta árvore. No caso, como tudo é um aprendizado, vamos arregaçar as mangas :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Análise descritiva: vale a pena preencher ```sex``` com modelo?<a name=\"2.1\"></a>\n",
    "[Voltar para o índice](#topo)  \n",
    "\n",
    "Em primeiro lugar, precisamos tentar entender se \"vale a pena\" fazer essa árvore. Intuitivamente, entendemos que os pinguins devem ter características bem diferentes no macho e na fêmea, a começar do peso. Vamos ver se os dados indicam isto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "sns.set_theme(style=\"ticks\")\n",
    "\n",
    "sns.boxplot(data=pg, x='species', hue=\"sex\", y='bill_length_mm')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pelo visto sim, machos e fêmeas possuem medidas bem diferentes dada a espécie, principalmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Modelo de preenchimento<a name=\"2.2\"></a>\n",
    "[Voltar para o índice](#topo)  \n",
    "\n",
    "Vamos então para o modelo de imputação de dados. O primeiro passo é **preparar a base para classificar sexo**. Não vamos perder o objetivo de vista: agora queremos fazer um modelo para prever sexo, para imputar os valores faltantes. Vamos lá:\n",
    "\n",
    "- Vamos retirar a variável ```sex``` da base\n",
    "- Utilizar o ```get_dummies()``` para criar as variáveis dummy de ```species``` e ```island```\n",
    "- Dividir a base em treino e teste\n",
    "- Fazer a pós poda pelo ccp-alpha\n",
    "- Classificar a base original para não perder as 9 observações\n",
    "\n",
    "Sim, dá um trabalhinho, mas com o tempo isso tudo vai ficando mais automático ;)\n",
    "\n",
    "Pois é, o nosso objetivo principal aqui é **aprender**. Caso contrário, seria absolutamente legítimo você decidir não fazer isto porque acha que não vale o custo vs benefício - aliás, esse é um julgamento muito útil para o cientista de dados ;)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Eliminando *missings* para a construção do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "pg2 = pg1[~pg1['sex'].isna()]\n",
    "pg2.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "pg2.isna().sum()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Criando *dummies* e separando bases de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "source": [
    "y0 = pg2.sex\n",
    "X0 = pd.get_dummies(pg2.drop(columns = ['sex']), drop_first=True)\n",
    "\n",
    "X0_train, X0_test, y0_train, y0_test = train_test_split(X0, y0)\n",
    "X0.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Construindo a árvore para classificar ```sex```\n",
    "A célula abaixo monta a árvore, treina \"deixando ela ser feliz\" (sem limite de profundidade, número de observações ou complexidade). Também salva os *ccp alpahs* para fazermos a pós poda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "clf0 = DecisionTreeClassifier(random_state=42)\n",
    "path = clf0.cost_complexity_pruning_path(X0_train, y0_train)\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Realiza a pós poda\n",
    "Sobre a árvore acima, que é super complexa, vamos obter árvores derivadas e menos complexas seguindo o caminho indicado pelo custo de complexidade (o *ccp alpha*). Para cada árvore derivada, vamos avaliar a métrica de desempenho (no caso, a acurácia), e escolher a melhor árvore para fazer a imputação. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "clfs0 = []\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    clf0 = DecisionTreeClassifier(random_state=2360873, ccp_alpha=ccp_alpha).fit(X0_train, y0_train)\n",
    "    clfs0.append(clf0)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos montar abaixo um gráfico que já vimos na aula de árvores binárias: para cada poda indicada pelo *ccp*, colocamos a métrica de desempenho da árvore na base de desenvolvimento e na base de testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "train_scores = [clf0.score(X0_train, y0_train) for clf0 in clfs0]\n",
    "test_scores  = [clf0.score(X0_test, y0_test)   for clf0 in clfs0]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"alpha\")\n",
    "ax.set_ylabel(\"Acurácia\")\n",
    "ax.set_title(\"Acurácia x alpha do conjunto de dados de treino e teste\")\n",
    "ax.plot(ccp_alphas, train_scores, marker='o', label=\"treino\",\n",
    "        drawstyle=\"steps-post\")\n",
    "ax.plot(ccp_alphas, test_scores, marker='o', label=\"teste\",\n",
    "        drawstyle=\"steps-post\")\n",
    "ax.legend()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pronto. Abaixo tem uma \"firula\": Eu quero a melhor árvore, sim, mas se houverem empates, a que tenha a menor complexidade. Isso significa que eu quero pegar a maior métrica de desempenho no objeto ```test_scores```, mas se houver empates, queremos a primeira ocorrência desse máximo **da direita para a esquerda**.\n",
    "\n",
    "Esse é um ótimo quebra cabeças de Python :) Abaixo temos um código bem pythonico que resolve isso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "ind_melhor_arvore = len(test_scores) - test_scores[::-1].index(max(test_scores)) - 1\n",
    "melhor_arvore = clfs0[ind_melhor_arvore]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Substituindo os missings\n",
    "\n",
    "Agora que fizemos a árvore para a variável ```sex```, vamos utilizar esta regra para substituir os valores missing na base original. Aí você pode me perguntar: \"Por quê não fazemos para as outras 4 variávels?\" E eu respondo com outra pergunta: \"Séro? Você acha mesmo que vale a pena por 2 observações e sem ter muito com o que prever? Boa sorte então, pode fazer!\" Repito: sempre vale refletir se vale o esforço de se construir um modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Seleciona as variáveis a serem substituídas\n",
    "prever = pd.get_dummies(pg1.drop(columns = ['sex']), drop_first=True)\n",
    "prever_sex = prever[pg1['sex'].isna()]\n",
    "\n",
    "#faz a classificação conforme a árvore\n",
    "inputação_sex = melhor_arvore.predict(prever_sex)\n",
    "inputação_sex"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Faz a substituição propriamente dita\n",
    "pg1.loc[pg1['sex'].isna(), 'sex'] = inputação_sex\n",
    "\n",
    "print(pg1.shape)\n",
    "pg1.isna().sum()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos salvar esta base de dados tratada, para uso futuro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "source": [
    "pg1.to_csv('pg1.csv', index=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. Classificação multinomial<a name=\"3\"></a>\n",
    "[Voltar para o índice](#topo)  \n",
    "\n",
    "Pronto, agora sim vamos para o tema principal: construir um algoritmo que classifique a **espécie** do pinguim em uma das três que aparecem na base de dados. A mecânica aqui é MUITO parecida com a classificação binária, basta utilizarmos generalizações das funções de impureza que comportem mais de duas classes e pronto: podemos usar o mesmo algoritmo.\n",
    "\n",
    "Vamos seguir aqui passos bem parecidos:\n",
    "- Tratar *missings* (acabamos de fazer isso)\n",
    "- Criar *dummies*\n",
    "- Construir a árvore (e deixa-la \"ser feliz\")\n",
    "- Realizar a pós-poda e obter a árvore \"ótima\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "source": [
    "pg1.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "source": [
    "X = pd.get_dummies(pg1.drop(columns = ['species', 'island']), drop_first=True)\n",
    "y = pg1['species']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "source": [
    "y_train.value_counts()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 A árvore<a name=\"3.1\"></a>\n",
    "[Voltar para o índice](#topo)\n",
    "\n",
    "A árvore é bem semelhante à que já conhecemos, mas com mais de uma alternativa de resposta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "source": [
    "clf = DecisionTreeClassifier(random_state=2360873, max_depth=3).fit(X_train, y_train)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "source": [
    "import graphviz\n",
    "from sklearn.tree import export_graphviz\n",
    "# DOT data\n",
    "dot_data = export_graphviz(clf, out_file=None, \n",
    "                                feature_names=X_train.columns,  \n",
    "                                class_names=['Adelie', 'Chinstrap', 'Gentoo'],\n",
    "                                filled=True)\n",
    "\n",
    "# Draw graph\n",
    "graph = graphviz.Source(dot_data, format=\"png\") \n",
    "graph\n",
    "\n",
    "# Decision Tree Classifier from scikit-learn sklearn visualized with graphviz in Python"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avaliando a árvore completa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 3.2 Pós-poda<a name=\"3.2\"></a>\n",
    "[Voltar para o índice](#topo)  \n",
    "\n",
    "Essa etapa é bem parecida com o que já fizemos. Vamos observar os \"caminhos de poda\" da árvore \"grande\", avaliar uma métrica de qualidade do modelo na base de testes, e selecionar a melhor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "source": [
    "caminho = DecisionTreeClassifier(random_state=2360873).cost_complexity_pruning_path(X_train, y_train)\n",
    "ccp_alphas, impurities = caminho.ccp_alphas, path.impurities"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "source": [
    "clfs = []\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    clf = DecisionTreeClassifier(random_state=2360873, ccp_alpha=ccp_alpha).fit(X_train, y_train)\n",
    "    clfs.append(clf)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "source": [
    "train_scores = [clf.score(X_train, y_train) for clf in clfs]\n",
    "test_scores = [clf.score(X_test, y_test) for clf in clfs]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"alpha\")\n",
    "ax.set_ylabel(\"Acurácia\")\n",
    "ax.set_title(\"Acurácia x alpha do conjunto de dados de treino e teste\")\n",
    "ax.plot(ccp_alphas, train_scores, marker='o', label=\"treino\",\n",
    "        drawstyle=\"steps-post\")\n",
    "ax.plot(ccp_alphas, test_scores, marker='o', label=\"teste\",\n",
    "        drawstyle=\"steps-post\")\n",
    "ax.legend()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Selecionando a melhor árvore<a name=\"3.3\"></a>\n",
    "[Voltar para o índice](#topo)  \n",
    "\n",
    "Vamos pegar a melhor árvore utilizando a mesma lógica da árvore que usamos para preencher os registros faltantes na variável ```sex```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "source": [
    "ind_melhor_arvore = len(test_scores) - test_scores[::-1].index(max(test_scores)) - 1\n",
    "melhor_arvore = clfs[ind_melhor_arvore]\n",
    "melhor_arvore"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Avaliando o resultado<a name=\"3.3\"></a>\n",
    "[Voltar para o índice](#topo)  \n",
    "\n",
    "Agora vamos avaliar o resultado da nossa classificação utilizanod a acrurácia, na base de testes. Para um visual um pouco melhor, vamos utilizar a matriz de confusão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "plot_confusion_matrix(melhor_arvore, X_test, y_test);"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensacional esse resultado não? A taxa de acertos é impressionante! Até era de se esperar algo bom pela análise descritiva.\n",
    "\n",
    "Mas, para refletir, o gancho para a próxima aula:\n",
    "\n",
    "Será que \"demos sorte\" de a base de testes ter esse desempenho?  \n",
    "Com outra base teriamos o mesmo desempenho?  \n",
    "Como podemos obter uma métrica mais \"confiável\" do desempenho desse algoritmo?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
